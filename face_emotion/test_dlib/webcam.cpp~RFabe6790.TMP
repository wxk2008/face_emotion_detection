// The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt
/*

This example program shows how to find frontal human faces in an image and
estimate their pose.  The pose takes the form of 68 landmarks.  These are
points on the face such as the corners of the mouth, along the eyebrows, on
the eyes, and so forth.


This example is essentially just a version of the face_landmark_detection_ex.cpp
example modified to use OpenCV's VideoCapture object to read from a camera instead
of files.


Finally, note that the face detector is fastest when compiled with at least
SSE2 instructions enabled.  So if you are using a PC with an Intel or AMD
chip then you should enable at least SSE2 instructions.  If you are using
cmake to compile this program you can enable them by using one of the
following commands when you create the build project:
cmake path_to_dlib_root/examples -DUSE_SSE2_INSTRUCTIONS=ON
cmake path_to_dlib_root/examples -DUSE_SSE4_INSTRUCTIONS=ON
cmake path_to_dlib_root/examples -DUSE_AVX_INSTRUCTIONS=ON
This will set the appropriate compiler options for GCC, clang, Visual
Studio, or the Intel compiler.  If you are using another compiler then you
need to consult your compiler's manual to determine how to enable these
instructions.  Note that AVX is the fastest but requires a CPU from at least
2011.  SSE4 is the next fastest and is supported by most current machines.
*/

#include <dlib/opencv.h>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2\opencv.hpp>
#include <dlib/image_processing/frontal_face_detector.h>
#include <dlib/image_processing/render_face_detections.h>
#include <dlib/image_processing.h>
#include <dlib/gui_widgets.h>
#include <opencv\ml.h>
#include <opencv2\ml\ml.hpp>
#include <opencv2\imgproc\imgproc.hpp>
#include <opencv2\opencv.hpp>
#include <opencv\cv.h>
#include <opencv2\calib3d\calib3d.hpp>
#include <opencv2\highgui\highgui.hpp>
#include <opencv2\opencv_modules.hpp>
#include <opencv2\ocl\ocl.hpp>
#include"svm.h"

using namespace dlib;
using namespace std;

//cv::Point cPoint[68];
cv::vector<cv::Point> cPoints;
double featureScaler;
struct svm_node *node;
struct svm_model *svmModel;
char*mdFile = "face2.model";
cv::Point textArea;
cv::VideoCapture cap;



double innerBrowRaiser;     //AU 1
double outerBrowRaiser;     //AU 2
double browLower;           //AU 4
double upperLidRaiser;      //AU 5
double lidTightener;        //AU 7
double noseWrinkler;        //AU 9
double lipCornerPull;       //AU 12
double lipCornerDepress;    //AU 15
double lowerLipDepress;     //AU 16
double lipStretch;          //AU 20
double lipTightener;        //AU 23
double jawDrop;             //AU 26

double getDist(cv::Point p1, cv::Point p2)
{
	double r = sqrt((p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y));
	return r;
}

double getDistX(cv::Point p1, cv::Point p2)
{
	double r = abs(p1.x - p2.x);
	return r;
}

double getDistY(cv::Point p1, cv::Point p2)
{
	double r = abs(p1.y - p2.y);
	return r;
}


//emotion estimation

/*string emotion_estimation(cv::vector<cv::Point> cPoints)
{
	if ((svmModel = svm_load_model(mdFile)) == 0)
	{
		std::cout << "can not open model file!!" << std::endl;
		exit(0);
	}

	//allocate memory from svm node
	node = (struct svm_node *)malloc(64 * sizeof(struct svm_node));

	//loop until quit 
	bool fail = true;
	//assign feature scaler as the width of the face, which does not change in response to different expression
	featureScaler = (getDistX(cPoints[0], cPoints[16]) + getDistX(cPoints[1], cPoints[15]) + getDistX(cPoints[2], cPoints[14])) / 3;
	//assign action unit 1
	innerBrowRaiser = ((getDistY(cPoints[21], cPoints[27]) + getDistY(cPoints[22], cPoints[27])) / 2) / featureScaler;
	//assign action unit 2
	outerBrowRaiser = ((getDistY(cPoints[17], cPoints[27]) + getDistY(cPoints[26], cPoints[27])) / 2) / featureScaler;
	//assign action unit 4
	browLower = (((getDistY(cPoints[17], cPoints[27]) + getDistY(cPoints[18], cPoints[27]) +
		getDistY(cPoints[19], cPoints[27]) + getDistY(cPoints[20], cPoints[27]) +
		getDistY(cPoints[21], cPoints[27])) / 5 +
		(getDistY(cPoints[22], cPoints[27]) + getDistY(cPoints[23], cPoints[27]) +
		getDistY(cPoints[24], cPoints[27]) + getDistY(cPoints[25], cPoints[27]) +
		getDistY(cPoints[26], cPoints[27])) / 5) / 2) / featureScaler;
	//assign action unit 5
	upperLidRaiser = ((getDistY(cPoints[37], cPoints[27]) + getDistY(cPoints[44], cPoints[27])) / 2) / featureScaler;
	//assign action unit 7
	lidTightener = ((getDistY(cPoints[37], cPoints[41]) + getDistY(cPoints[38], cPoints[40])) / 2 +
		(getDistY(cPoints[43], cPoints[47]) + getDistY(cPoints[44], cPoints[46])) / 2) / featureScaler;
	//assign action unit 9
	noseWrinkler = (getDistY(cPoints[29], cPoints[27]) + getDistY(cPoints[30], cPoints[27])) / featureScaler;
	//assign action unit 12
	lipCornerPull = ((getDistY(cPoints[48], cPoints[33]) + getDistY(cPoints[54], cPoints[33])) / 2) / featureScaler;
	//assign action unit 16
	lowerLipDepress = getDistY(cPoints[57], cPoints[33]) / featureScaler;
	//assign action unit 20
	lipStretch = getDistX(cPoints[48], cPoints[54]) / featureScaler;
	//assign action unit 23
	lipTightener = (getDistY(cPoints[49], cPoints[59]) +
		getDistY(cPoints[50], cPoints[58]) +
		getDistY(cPoints[51], cPoints[57]) +
		getDistY(cPoints[52], cPoints[56]) +
		getDistY(cPoints[53], cPoints[55])) / featureScaler;
	//assign action unit 26
	jawDrop = getDistY(cPoints[8], cPoints[27]) / featureScaler;
	double class_nr = 0;
	int class_nr_int = 0;
	int i = 0;
	for (i = 0; i < 11; i++)
	{
		node[i].index = i;
	}
	node[11].index = -1;

	//assign value of nodes
	node[0].value = innerBrowRaiser;
	node[1].value = outerBrowRaiser;
	node[2].value = browLower;
	node[3].value = upperLidRaiser;
	node[4].value = lidTightener;
	node[5].value = noseWrinkler;
	node[6].value = lipCornerPull;
	node[7].value = lowerLipDepress;
	node[8].value = lipStretch;
	node[9].value = lipTightener;
	node[10].value = jawDrop;

	std::cout << innerBrowRaiser << endl;
	cout << outerBrowRaiser << endl;
	cout << browLower << endl;
	cout << upperLidRaiser << endl;
	cout << lidTightener << endl;
	cout << noseWrinkler << endl;
	cout << lipCornerDepress << endl;
	cout << lowerLipDepress << endl;
	cout << lipStretch << endl;
	cout << lipTightener << endl;
	cout << jawDrop << endl;

	string result;
	//predict the class
	//0: neutral face
	//1: happy
	//2: angry
	//3: disgust
	//-1 sad
	//-2 suprise
	//-3 fear
	/*double result_pro[7];
	double result_1 = svm_predict_probability(svmModel, node, result_pro);
	std::cout << "final" << result_1 << std::endl;
	for (int i = 0; i < 7; i++)
	{
		std::cout << result_pro[i] << std::endl;
	}*/



	/*class_nr = svm_predict(svmModel, node);
	class_nr_int = (int)class_nr;
	if (class_nr_int == 2) {
		//std::cout << "Angry" << std::endl;
		result = "Angry";

	}
	else if (class_nr_int == 1){
		//std::cout << "Happy" << std::endl;
		result = "happy";
	}
	else if (class_nr_int == 3){
		//std::cout << "Disgust" << std::endl;
		result = "Disgust";
	}
	else if (class_nr_int == -1){
		//std::cout << "Sad" << std::endl;
		result = "Sad";
	}
	else if (class_nr_int == -2){
		//std::cout << "Surprise" << std::endl;
		result = "Surprise";
	}
	else if (class_nr_int == -3){
		//std::cout << "Fear" << std::endl;
		result = "Fear";
	}
	else
	{
		//std::cout << "Neutral" << std::endl;
		result = "Neutral";
	}
}*/



//绘制脸部的一些特征轮廓
void my_drawEdge(cv::Mat img, std::vector<cv::Point> points)
{

	//assign feature scaler as the width of the face, which does not change in response to different expression
	//featureScaler = (getDistX(cPoints[0], cPoints[16]) + getDistX(cPoints[1], cPoints[15]) + getDistX(cPoints[2], cPoints[14])) / 3;
	//cv::line(img, points[0], points[16], cv::Scalar(255, 0, 0), 3);
	//cv::line(img, points[1], points[15], cv::Scalar(255, 0, 0), 3);
	//cv::line(img, points[2], points[14], cv::Scalar(255, 0, 0), 3);

	int line_width = 1;
	cv::line(img, points[21], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[22], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[21], points[22], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[17], points[18], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[18], points[19], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[19], points[20], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[20], points[21], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[22], points[23], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[23], points[24], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[24], points[25], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[25], points[26], cv::Scalar(255, 0, 0), line_width);


	
	cv::line(img, points[17], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[26], points[27], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[17], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[18], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[19], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[21], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[22], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[23], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[24], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[25], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[26], points[27], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[37], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[44], points[27], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[37], points[41], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[38], points[40], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[43], points[47], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[44], points[46], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[29], points[27], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[30], points[27], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[48], points[33], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[54], points[33], cv::Scalar(255, 0, 0), line_width);

	cv::line(img, points[57], points[33], cv::Scalar(255, 0, 0), line_width);
	
	cv::line(img, points[48], points[54], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[48], points[17], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[54], points[26], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[30], points[17], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[30], points[26], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[48], points[59], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[59], points[58], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[58], points[57], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[57], points[56], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[56], points[55], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[55], points[54], cv::Scalar(255, 0, 0), line_width);


	cv::line(img, points[49], points[59], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[50], points[58], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[51], points[57], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[52], points[56], cv::Scalar(255, 0, 0), line_width);
	cv::line(img, points[53], points[55], cv::Scalar(255, 0, 0), line_width);


}


frontal_face_detector detector = get_frontal_face_detector();
shape_predictor pose_model;


std::vector<double> train_data(string imgPath){

	deserialize("shape_predictor_68_face_landmarks.dat") >> pose_model;
	cv::Mat faceImg = cv::imread(imgPath.c_str());
	std::vector<double> data;
	std::vector<cv::Point>points;
	cv_image<bgr_pixel> cimg(faceImg);
	std::vector<rectangle> faces = detector(cimg);
	if (faces.size() == 0)
	{
		std::cout << "can't detect the face" << endl;
		exit(0);
	}
	
	std::vector<full_object_detection> shapes;
	for (int i = 0; i < faces.size(); i++)
	{
		full_object_detection shape = pose_model(cimg, faces[i]);
		shapes.push_back(shape);
	}

	
	full_object_detection shape = shapes[0];
	for (int i = 0; i < 68; i++)
	{
		cv::Point2f temp;
		temp.x = shape.part(i)(0);
		temp.y = shape.part(i)(1);
		points.push_back(temp);
	}
	std::cout << "point_size" << points.size() << std::endl;
	//assign feature scaler as the width of the face, which does not change in response to different expression
	featureScaler = (getDistX(points[0], points[16]) + getDistX(points[1], points[15]) + getDistX(points[2], points[14])) / 3;
	//assign action unit 1
	innerBrowRaiser = ((getDistY(points[21], points[27]) + getDistY(points[22], points[27])) / 2) / featureScaler;
	//assign action unit 2
	outerBrowRaiser = ((getDistY(points[17], points[27]) + getDistY(points[26], points[27])) / 2) / featureScaler;
	//assign action unit 4
	browLower = (((getDistY(points[17], points[27]) + getDistY(points[18], points[27]) +
		getDistY(points[19], points[27]) + getDistY(points[20], points[27]) +
		getDistY(points[21], points[27])) / 5 +
		(getDistY(points[22], points[27]) + getDistY(points[23], points[27]) +
		getDistY(points[24], points[27]) + getDistY(points[25], points[27]) +
		getDistY(points[26], points[27])) / 5) / 2) / featureScaler;
	//assign action unit 5
	upperLidRaiser = ((getDistY(points[37], points[27]) + getDistY(points[44], points[27])) / 2) / featureScaler;
	//assign action unit 7
	lidTightener = ((getDistY(points[37], points[41]) + getDistY(points[38], points[40])) / 2 +
		(getDistY(points[43], points[47]) + getDistY(points[44], points[46])) / 2) / featureScaler;
	//assign action unit 9
	noseWrinkler = (getDistY(points[29], points[27]) + getDistY(points[30], points[27])) / featureScaler;
	//assign action unit 12
	lipCornerPull = ((getDistY(points[48], points[33]) + getDistY(points[54], points[33])) / 2) / featureScaler;
	//assign action unit 16
	lowerLipDepress = getDistY(points[57], points[33]) / featureScaler;
	//assign action unit 20
	lipStretch = getDistX(points[48], points[54]) / featureScaler;
	//assign action unit 23
	lipTightener = (getDistY(points[49], points[59]) +
		getDistY(points[50], points[58]) +
		getDistY(points[51], points[57]) +
		getDistY(points[52], points[56]) +
		getDistY(points[53], points[55])) / featureScaler;
	//assign action unit 26
	jawDrop = getDistY(points[8], points[27]) / featureScaler;

	
	data.push_back(innerBrowRaiser);
	data.push_back(outerBrowRaiser);
	data.push_back(browLower);
	data.push_back(upperLidRaiser);
	data.push_back(lidTightener);
	data.push_back(noseWrinkler);
	data.push_back(lipCornerDepress);
	data.push_back(lowerLipDepress);
	data.push_back(lipStretch);
	data.push_back(lipTightener);
	data.push_back(jawDrop);

	return data;
}


double data_org[10][13] =
{ 
	1, 0.708333, 1, 1, -0.320755, -0.105023, -1, 1, -0.419847, -1, -0.225806, 0, 1,
	-1, 0.583333, -1, 0.333333, -0.603774, 1, -1, 1, 0.358779, -1, -0.483871, 0, -1,
	1, 0.166667, 1, -0.333333, -0.433962, -0.383562, -1, -1, 0.0687023, -1, -0.903226, -1, -1,
	-1, 0.458333, 1, 1, -0.358491, -0.374429, -1, -1, -0.480916, 1, -0.935484, 0, -0.333333,
	-1, 0.875, -1, -0.333333, -0.509434, -0.347032, -1, 1, -0.236641, 1, -0.935484, -1, -0.333333,
	-1, 0.5, 1, 1, -0.509434, -0.767123, -1, -1, 0.0534351, -1, -0.870968, -1, -1,
	1, 0.125, 1, 0.333333, -0.320755, -0.406393, 1, 1, 0.0839695, 1, -0.806452, 0, -0.333333,
	1, 0.25, 1, 1, -0.698113, -0.484018, -1, 1, 0.0839695, 1, -0.612903, 0, -0.333333,
	1, 0.291667, 1, 1, -0.132075, -0.237443, -1, 1, 0.51145, -1, -0.612903, 0, 0.333333,
	1, 0.416667, -1, 1, 0.0566038, 0.283105, -1, 1, 0.267176, -1, 0.290323, 0, 1

};


double test_data[] =
{
	0.25, 1, 1, -0.226415, -0.506849, -1, -1, 0.374046, -1, -0.83871, 0, -1
};


int main___test____________test__________test()
{
	/*string imgPath = "angry7.jpg";
	std::vector<double>data = train_data(imgPath);
	std::cout << "1::" << data[0] << std::endl;
	std::cout << "2::" << data[1] << std::endl;
	std::cout << "3::" << data[2] << std::endl;
	std::cout << "4::" << data[3] << std::endl;
	std::cout << "5::" << data[4] << std::endl;
	std::cout << "6::" << data[5] << std::endl;
	std::cout << "7::" << data[6] << std::endl;
	std::cout << "8::" << data[7] << std::endl;
	std::cout << "9::" << data[8] << std::endl;
	std::cout << "10::" << data[9] << std::endl;
	std::cout << "11::" << data[10] << std::endl;*/
	CvSVM svm;
	CvSVMParams param;
	param.svm_type = 100;
	param.kernel_type = 1;
	param.degree = 4;
	param.gamma = 4;
	param.coef0 = 1;
	CvMat *dataMat = cvCreateMat(10, 12, CV_32FC1);
	CvMat *labelMat = cvCreateMat(10, 1, CV_32SC1);
	for (int i = 0; i<10; i++)
	{
		for (int j = 0; j<12; j++)
		{
			cvSetReal2D(dataMat, i, j, data_org[i][j + 1]);
		}
		cvSetReal2D(labelMat, i, 0, data_org[i][0]);

	}
	svm.train(dataMat, labelMat, NULL, NULL, param);
	svm.save("svmResult.txt");
	CvMat *testMat = cvCreateMat(1, 12, CV_32FC1);

	for (int i = 0; i<12; i++)
	{
		cvSetReal2D(testMat, 0, i, test_data[i]);
	}

	float flag = 0;
	flag = svm.predict(testMat);
	cout << "testMat, flag = " << flag << endl;
	system("pause");
	cvReleaseMat(&dataMat);
	cvReleaseMat(&labelMat);
	cvReleaseMat(&testMat);
	return 0;
}

double template_landmark[32] = {
	0.0792396913815, 0.339223741112, 0.0829219487236, 0.456955367943,
	0.0967927109165, 0.575648016728, 0.122141515615, 0.691921601066,
	0.168687863544, 0.800341263616, 0.239789390707, 0.895732504778,
	0.325662452515, 0.977068762493, 0.422318282013, 1.04329000149,
	0.531777802068, 1.06080371126, 0.641296298053, 1.03981924107,
	0.738105872266, 0.972268833998, 0.824444363295, 0.889624082279,
	0.894792677532, 0.792494155836, 0.939395486253, 0.681546643421,
	0.96111933829, 0.562238253072, 0.970579841181, 0.441758925744
};

int main()
{
	deserialize("shape_predictor_68_face_landmarks.dat") >> pose_model;
	cv::Mat face1 = cv::imread("happy10.jpg");
	cv::Mat face2 = cv::imread("white.jpg");
	cv::Point2f src[16];
	cv::Point2f dst[16];
	//对人脸头像进行归一化处理
	dlib::array<unsigned>face1_chip;
	dlib::array<unsigned>face2_chip;
	cv::Mat face1_gray;
	cv::Mat face2_gray;
	cv::resize(face1, face1, cv::Size(640, 480));
	cv::resize(face2, face2, cv::Size(640, 480));
	int IMAGE_WIDTH = 640;
	int IMAGE_HEIGHT = 480;
	int IMAGE_WIDTH_STD = 90;
	int IMAGE_HEIGHT_STD = 90;
	for (int i = 0; i < 16; i++)
	{
		src[i] = cv::Point2f(template_landmark[i * 2] * 90 + IMAGE_HEIGHT / 2, template_landmark[i * 2 + 1] * 90 + IMAGE_WIDTH / 2);
		dst[i] = cv::Point2f(template_landmark[i * 2] * IMAGE_HEIGHT_STD, template_landmark[2 * i + 1] * IMAGE_WIDTH_STD);
	}
	cv::Mat warp_mat = cv::estimateRigidTransform(src, dst, false);

	//cv::Mat warp_mat = cv::getAffineTransform(src, dst);
	cv::Mat wrap_img(200, 200, CV_8UC3);
	cv::warpAffine(face1, wrap_img, warp_mat, wrap_img.size());
	cv::imshow("face", wrap_img);
	cv::cvtColor(face1, face1_gray, cv::COLOR_BGR2GRAY);
	cv::cvtColor(face2, face2_gray, cv::COLOR_BGR2GRAY);
	cv::equalizeHist(face1_gray, face1_gray);
	cv::equalizeHist(face2_gray, face2_gray);
	//cv::imshow("1", face1_gray);
	//cv::imshow("2", face2_gray);
	cv::waitKey(0);



	return 0;
}
int main_______________________________test____________________test(){

	deserialize("shape_predictor_68_face_landmarks.dat") >> pose_model;

	//把所有的脸部截取出来提高识别的准确率

	double duration;
	duration = static_cast<double>(cv::getTickCount());

	cv::Mat img = cv::imread("happy10.jpg");
	//cv::Mat img;
	cv::Mat friFrame;

	/*if (!(cap.open(0)))
	{
		std::cout << "please set your camera!!!!" << std::endl;
		exit(0);
	}*/

	//for (int i = 0;; i++)
	//{
		//cap >> img;
		//if (i == 0)
		//{
			img.copyTo(friFrame);
			//points.clear();
			cv_image<bgr_pixel> cimg(friFrame);
			//cv_image<bgr_pixel> cimg(img);
			std::vector<rectangle> faces = detector(cimg);
			if (faces.size() == 0)
			{
				std::cout << "can't detect the face" << endl;
				exit(0);
			}
			//std::cout << faces.size() << std::endl;
			std::vector<full_object_detection> shapes;
			for (int i = 0; i < faces.size(); i++)
			{
				full_object_detection shape = pose_model(cimg, faces[i]);
				shapes.push_back(shape);
			}

			cout << "face size" << faces.size() << endl;
			/*for (int i = 0; i < shapes.size(); i++)
			{
				full_object_detection shape = shapes[i];
				rectangle faceRect = shape.get_rect();
				int width = faceRect.width();
				int height = faceRect.height();
				int point_x = faceRect.left();
				int point_y = faceRect.top();
				cv::Rect face_rect(point_x, point_y, width, height);
				cv::Mat faceRoi = img(face_rect);
				cv::imshow("faceROI", faceRoi);
				//cv::imwrite("roi.jpg", faceRoi);
				cv::waitKey(600);

				for (int j = 0; j < 68; j++)
				{
					cv::Point2f temp;
					temp.x = shape.part(i)(0);
					temp.y = shape.part(i)(1);
					points.push_back(temp);
				}
			}*/

			full_object_detection shape = shapes[0];
			//std::cout << shape.part(1).size();
			for (int i = 0; i < 68; i++)
			{
				//std::cout << shape.part(i).size();
				cv::Point2f temp;
				temp.x = shape.part(i)(0);
				temp.y = shape.part(i)(1);
				cPoints.push_back(temp);
				//cv::line(img, cv::Point(shape.part(67)(0), shape.part(67)(1)), temp, cv::Scalar(0, 0, 255));

			}


			cv::imshow("org_face", img);
			my_drawEdge(img, cPoints);
			cv::imshow("face_edge", img);
			cv::waitKey(0);
			//assign feature scaler as the width of the face, which does not change in response to different expression
			featureScaler = (getDistX(cPoints[0], cPoints[16]) + getDistX(cPoints[1], cPoints[15]) + getDistX(cPoints[2], cPoints[14])) / 3;
			//assign action unit 1
			innerBrowRaiser = ((getDistY(cPoints[21], cPoints[27]) + getDistY(cPoints[22], cPoints[27])) / 2) / featureScaler;
			//assign action unit 2
			outerBrowRaiser = ((getDistY(cPoints[17], cPoints[27]) + getDistY(cPoints[26], cPoints[27])) / 2) / featureScaler;
			//assign action unit 4
			browLower = (((getDistY(cPoints[17], cPoints[27]) + getDistY(cPoints[18], cPoints[27]) +
				getDistY(cPoints[19], cPoints[27]) + getDistY(cPoints[20], cPoints[27]) +
				getDistY(cPoints[21], cPoints[27])) / 5 +
				(getDistY(cPoints[22], cPoints[27]) + getDistY(cPoints[23], cPoints[27]) +
				getDistY(cPoints[24], cPoints[27]) + getDistY(cPoints[25], cPoints[27]) +
				getDistY(cPoints[26], cPoints[27])) / 5) / 2) / featureScaler;
			//assign action unit 5
			upperLidRaiser = ((getDistY(cPoints[37], cPoints[27]) + getDistY(cPoints[44], cPoints[27])) / 2) / featureScaler;
			//assign action unit 7
			lidTightener = ((getDistY(cPoints[37], cPoints[41]) + getDistY(cPoints[38], cPoints[40])) / 2 +
				(getDistY(cPoints[43], cPoints[47]) + getDistY(cPoints[44], cPoints[46])) / 2) / featureScaler;
			//assign action unit 9
			noseWrinkler = (getDistY(cPoints[29], cPoints[27]) + getDistY(cPoints[30], cPoints[27])) / featureScaler;
			//assign action unit 12
			lipCornerPull = ((getDistY(cPoints[48], cPoints[33]) + getDistY(cPoints[54], cPoints[33])) / 2) / featureScaler;
			//assign action unit 16
			lowerLipDepress = getDistY(cPoints[57], cPoints[33]) / featureScaler;
			//assign action unit 20
			lipStretch = getDistX(cPoints[48], cPoints[54]) / featureScaler;
			//assign action unit 23
			lipTightener = (getDistY(cPoints[49], cPoints[59]) +
				getDistY(cPoints[50], cPoints[58]) +
				getDistY(cPoints[51], cPoints[57]) +
				getDistY(cPoints[52], cPoints[56]) +
				getDistY(cPoints[53], cPoints[55])) / featureScaler;
			//assign action unit 26
			jawDrop = getDistY(cPoints[8], cPoints[27]) / featureScaler;

			if ((svmModel = svm_load_model(mdFile)) == 0)
			{
				std::cout << "can not open model file!!" << std::endl;
				exit(0);
			}

			//allocate memory from svm node
			node = (struct svm_node *)malloc(64 * sizeof(struct svm_node));

			double class_nr = 0;
			int class_nr_int = 0;
			int i = 0;
			for (i = 0; i < 11; i++)
			{
				node[i].index = i;
			}
			node[11].index = -1;

			//assign value of nodes
			node[0].value = innerBrowRaiser;
			node[1].value = outerBrowRaiser;
			node[2].value = browLower;
			node[3].value = upperLidRaiser;
			node[4].value = lidTightener;
			node[5].value = noseWrinkler;
			node[6].value = lipCornerPull;
			node[7].value = lowerLipDepress;
			node[8].value = lipStretch;
			node[9].value = lipTightener;
			node[10].value = jawDrop;

			std::cout << innerBrowRaiser << endl;
			cout << outerBrowRaiser << endl;
			cout << browLower << endl;
			cout << upperLidRaiser << endl;
			cout << lidTightener << endl;
			cout << noseWrinkler << endl;
			cout << lipCornerDepress << endl;
			cout << lowerLipDepress << endl;
			cout << lipStretch << endl;
			cout << lipTightener << endl;
			cout << jawDrop << endl;
			//textArea = cv::Point(points[8].x - 50, points[8].y + 50)
			//predict the class
			//0: neutral face
			//1: happy
			//2: angry
			//3: disgust
			//-1 sad
			//-2 suprise
			//-3 fear
			class_nr = svm_predict(svmModel, node);
			class_nr_int = (int)class_nr;

			if (class_nr_int == 2){
				std::cout << "angry" << std::endl;
			}
			else if (class_nr_int == 1)
			{
				std::cout << "happy" << std::endl;
			}
			else if (class_nr_int == 3)
			{
				std::cout << "disgust" << std::endl;
			}
			else if (class_nr_int == -1){
				std::cout << "sad" << std::endl;
			}
			else if (class_nr_int == -2)
			{
				std::cout << "surprise" << std::endl;
			}
			else if (class_nr_int == -3)
			{
				std::cout << "fear" << std::endl;
			}
			else
			{
				std::cout << "nature" << std::endl;
			}

			duration = static_cast<double>(cv::getTickCount()) - duration;
			duration /= cv::getTickFrequency(); // the elapsed time in ms
			std::cout << "time" << duration << std::endl;
		//}

		//cv::putText(img, preResult, textArea,1,3.0,cv::Scalar(255,0,0));
		//cv::imshow("test", img);
		//cv::waitKey(100);
	//}

	//cv::imshow("frist", friFrame);
	//cv::waitKey(0);

	
	return 0;
}


